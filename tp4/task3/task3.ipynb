{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff23ed64-24bc-4a24-888e-b0c4900f53cb",
   "metadata": {},
   "source": [
    "# Task 3: New Data Pipeline Using Delta Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5813d-a2be-4c3a-bf31-35477eea73d0",
   "metadata": {},
   "source": [
    "## Creating Delta Format Datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54deffc6-5cb1-4262-976c-e023483eac7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.11/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/gabrielbarros/.ivy2/cache\n",
      "The jars for the packages stored in: /home/gabrielbarros/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-de93ac5d-8bf5-466e-8e74-4fa193aecf2f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 204ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-de93ac5d-8bf5-466e-8e74-4fa193aecf2f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n",
      "25/02/05 20:59:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/05 20:59:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/02/05 20:59:15 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/02/05 20:59:15 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "25/02/05 20:59:15 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "25/02/05 20:59:30 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/02/05 20:59:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/05 20:59:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/05 20:59:52 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/05 20:59:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 20:59:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 20:59:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 20:59:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 20:59:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 20:59:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 20:59:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 20:59:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:00:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/05 21:00:28 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "Processing time for delta data lake: 80.50 seconds                              \n"
     ]
    }
   ],
   "source": [
    "! python3 /home/gabrielbarros/tp4/task3/create_delta_lake.py delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23235d8-3445-4803-8d84-0c5f26e4afc2",
   "metadata": {},
   "source": [
    "## Ingest V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c466437f-0439-4b7c-a6f7-4da70894b2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.11/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/gabrielbarros/.ivy2/cache\n",
      "The jars for the packages stored in: /home/gabrielbarros/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-216139e3-c7a6-4365-a5a3-6ad8d6b71dea;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 295ms :: artifacts dl 27ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-216139e3-c7a6-4365-a5a3-6ad8d6b71dea\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/36ms)\n",
      "25/02/05 21:00:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/05 21:00:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/02/05 21:00:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/02/05 21:00:37 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "25/02/05 21:00:37 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "25/02/05 21:00:58 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/02/05 21:01:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/05 21:01:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/05 21:01:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/05 21:01:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:01:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:02:14 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "25/02/05 21:02:14 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "25/02/05 21:02:15 WARN TaskMemoryManager: Failed to allocate a page (16777216 bytes), try again.\n",
      "25/02/05 21:02:15 ERROR Executor: Exception in task 3.0 in stage 232.0 (TID 1559)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.<init>(UnsafeSorterSpillReader.java:50)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.getReader(UnsafeSorterSpillWriter.java:159)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.getSortedIterator(UnsafeExternalSorter.java:555)\n",
      "\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:172)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:779)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1(SortAggregateExec.scala:62)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1$adapted(SortAggregateExec.scala:59)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec$$Lambda$3769/0x00007f27e90862e8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$3770/0x00007f27e90868a8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2569/0x00007f27e8dbaab8.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/02/05 21:02:15 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 3.0 in stage 232.0 (TID 1559),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.<init>(UnsafeSorterSpillReader.java:50)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.getReader(UnsafeSorterSpillWriter.java:159)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.getSortedIterator(UnsafeExternalSorter.java:555)\n",
      "\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:172)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:779)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1(SortAggregateExec.scala:62)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1$adapted(SortAggregateExec.scala:59)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec$$Lambda$3769/0x00007f27e90862e8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$3770/0x00007f27e90868a8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2569/0x00007f27e8dbaab8.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/02/05 21:02:15 WARN TaskSetManager: Lost task 3.0 in stage 232.0 (TID 1559) (cloud3 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.<init>(UnsafeSorterSpillReader.java:50)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.getReader(UnsafeSorterSpillWriter.java:159)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.getSortedIterator(UnsafeExternalSorter.java:555)\n",
      "\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:172)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:779)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1(SortAggregateExec.scala:62)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1$adapted(SortAggregateExec.scala:59)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec$$Lambda$3769/0x00007f27e90862e8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$3770/0x00007f27e90868a8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2569/0x00007f27e8dbaab8.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "25/02/05 21:02:15 ERROR TaskSetManager: Task 3 in stage 232.0 failed 1 times; aborting job\n",
      "25/02/05 21:02:15 ERROR Inbox: Ignoring error\n",
      "java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@5c19ad75 rejected from java.util.concurrent.ThreadPoolExecutor@e3b2ce5[Shutting down, pool size = 10, active threads = 8, queued tasks = 0, completed tasks = 1556]\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2065)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:833)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1365)\n",
      "\tat org.apache.spark.executor.Executor.launchTask(Executor.scala:311)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1(LocalSchedulerBackend.scala:93)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1$adapted(LocalSchedulerBackend.scala:91)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:91)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:74)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2c/temp_shuffle_40e0d1bb-4278-4f01-beab-89ea09faedba\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3d/temp_shuffle_2d70c9ea-5d7f-4ecd-9e43-4ac05edc8610\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2b/temp_shuffle_e768ccc9-e15e-4dfc-9120-06fd0ba9b6e8\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/12/temp_shuffle_c64db1ff-5f9b-494d-a697-5f76cf621b07\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2a/temp_shuffle_cf0fa8b4-6e6d-4b08-aa49-3af83a542257\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3b/temp_shuffle_925e7936-dd4f-49ce-8139-ad5cfce43848\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/08/temp_shuffle_161fff51-024e-4764-a363-9a3e95ed775b\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/06/temp_shuffle_6ae703f3-09df-47bb-be55-6f0b271a6f88\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2e/temp_shuffle_d173dedb-45ef-4541-a894-e39298691568\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2e/temp_shuffle_02cf67cc-ef6e-4b36-a45f-1da865d4b0b9\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/08/temp_shuffle_b7d33375-1585-4015-bf1e-c5f64ceab553\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/14/temp_shuffle_4ddbe41f-5c4a-43c0-8e13-2d3d1438b26b\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/30/temp_shuffle_b488ed7c-efb5-4f5a-a8ae-905975ee2194\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1f/temp_shuffle_f87e96f7-85f4-46bc-95f1-b67bb97fee5a\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/38/temp_shuffle_c7affc12-d988-404d-ac03-fe6b4a373973\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/11/temp_shuffle_f6e0a761-7191-4c74-819c-8f5db221a651\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/21/temp_shuffle_4a90a273-488d-4a2a-a08c-7d1d29625717\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/13/temp_shuffle_09a88a60-bd75-4d0c-adbb-c2823050a658\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/11/temp_shuffle_95c6baec-a31a-402e-9d90-e607f3457668\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/18/temp_shuffle_136cf110-ddc3-4cb1-8b0c-923653f9dc5f\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/39/temp_shuffle_d77b44f7-87dd-4b09-ab77-a4123ac31351\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/12/temp_shuffle_ba20b015-30f9-4f43-baba-ed459c165683\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/20/temp_shuffle_0c509199-525a-4c07-b76a-fc4f669238a0\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0a/temp_shuffle_a5ea70f6-394c-4491-b125-761c65d79023\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1e/temp_shuffle_22bd7c62-ac9d-4ec1-a4b8-38b76756f5e4\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/31/temp_shuffle_69492ed3-796f-4528-a2fa-f440a482d558\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/09/temp_shuffle_d5326530-bfe7-49aa-a9b3-5c1a0ae2a856\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3c/temp_shuffle_20eb4e08-278c-475f-97d4-0b6626bd979d\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/14/temp_shuffle_d0f2b40d-fafc-4940-b3ba-e47f18d9f9a8\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/15/temp_shuffle_3ec5b808-7679-4902-8044-2e56615f2c36\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2b/temp_shuffle_3c7025ea-7ef7-4f7e-9f3d-698a03d0fb57\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/37/temp_shuffle_d9425a7c-069d-4abb-928b-7e58714a6f5a\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0e/temp_shuffle_f64614ad-72bc-4c14-b3b1-ab58d381ef28\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1a/temp_shuffle_e76fed87-d9bd-4bdb-810a-79a92e21db88\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/32/temp_shuffle_1fb44799-99c2-40b1-9896-ca96e1e369cb\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/28/temp_shuffle_74bf326f-9524-4e55-becb-379ff1a8a3ab\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/19/temp_shuffle_1dfdedab-9bb1-44e1-a50b-28e287d6ce2c\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/14/temp_shuffle_01e8dc4b-433b-4bfe-96ea-26de95a6c290\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1d/temp_shuffle_6d538a7c-9613-45f9-9446-0cac5b0e7a80\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/06/temp_shuffle_b77a434e-8ae3-44ab-877c-f3ffe9fd91b2\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0e/temp_shuffle_a451f41c-548a-45bb-a85b-f1485e7ce359\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/34/temp_shuffle_0e9161b0-7023-4aad-8caf-d163e92a1f85\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0b/temp_shuffle_e759d811-8aa6-4460-8a73-cba11ad50229\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/19/temp_shuffle_00297cd5-a34f-43ea-9499-a8a575f1f20f\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/24/temp_shuffle_64bc47c4-1f1b-46e9-a4db-b7df07634a1b\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/35/temp_shuffle_03d7afc0-3dc4-4e1b-a0be-755c621c9adf\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/18/temp_shuffle_2b0d1fab-bd15-4dd7-a5d4-71f01eb42826\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/27/temp_shuffle_f4f8a176-72b1-4e28-8c0b-e52d5f0e6e22\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/16/temp_shuffle_f3ff5a72-a887-4c45-8c24-5b69c64a19d0\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/38/temp_shuffle_cf3f09e6-0bfa-4640-86e7-de9e29e88029\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/06/temp_shuffle_49dc6b88-1869-4f33-9df8-1394d9a72b13\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/30/temp_shuffle_6a1bc962-a11d-4d37-9d2e-74b69aaf6e5f\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/04/temp_shuffle_00597f24-a06e-4480-9a34-4b27417ce361\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/17/temp_shuffle_2a92bd24-dc99-4c58-8530-c0c2b0a63cb4\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2b/temp_shuffle_55dd8727-277b-4e4d-b1eb-eddf5cc6c068\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0d/temp_shuffle_aa65e8a2-5314-4a93-9458-125da9063f0f\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/29/temp_shuffle_9515c756-c1a4-45be-9a5b-f4faaa70e3c6\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3a/temp_shuffle_7128ddfc-e0b5-4753-9f47-37c1b329651a\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/18/temp_shuffle_c3ec5e08-e1ca-4039-a251-b487531b8e70\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/15/temp_shuffle_d8c6bcaa-4386-498c-9661-56c555adec25\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/10/temp_shuffle_809799bf-0ad7-4f12-bba5-ff3248098e3d\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/04/temp_shuffle_abf3f601-e01d-4ec3-882a-25cbab87eb67\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1d/temp_shuffle_a2c4f2f8-b6c2-4d08-8592-1e33dea8a42f\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3d/temp_shuffle_e11ac553-dd41-4358-a308-1b132f5efa8a\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/26/temp_shuffle_7cd686e8-0be0-4621-aba6-136d093213fd\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/07/temp_shuffle_be7f9bd6-72dc-4fad-993d-caebf9585e5e\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/26/temp_shuffle_e2408d80-82f3-4aa3-8e4a-838f11a62530\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/16/temp_shuffle_8314227b-c1d4-4339-beaa-82e308ce3724\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1d/temp_shuffle_33c5293e-c674-4158-b002-6a935e0e00eb\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3e/temp_shuffle_096e815a-a0d3-42ef-ba0b-6a576b23e681\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/34/temp_shuffle_d48031ab-067f-4003-b103-cd2667443870\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0c/temp_shuffle_57b36862-6101-47cc-8e6c-80cbd802e9ea\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/04/temp_shuffle_34717cee-683e-49b0-ae45-d4dc70cd59eb\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/02/temp_shuffle_8435318f-6078-4521-89ae-427849efb98c\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/06/temp_shuffle_de170bbc-af4a-47a0-ae74-7e9943c3d2af\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1b/temp_shuffle_d8ddc86d-997c-4e08-819b-f63c6fff6db6\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/34/temp_shuffle_5fcb87cf-c544-4ab1-b2a4-cb0d04627064\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/11/temp_shuffle_8670dd79-0acb-4f62-8661-5f53108259c7\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1d/temp_shuffle_da87acdf-c0ab-43f3-b38b-331aa219d92c\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/22/temp_shuffle_8fd2ed88-cc1c-411c-a68a-103462d682e0\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3d/temp_shuffle_a1d8f1a8-8a8a-4be6-b469-127482f95bc9\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3b/temp_shuffle_b6cf27a6-886e-4a3e-965d-e9035e9f87e1\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/28/temp_shuffle_b3d09e4e-8a7f-4dca-b530-0c733abed83f\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2f/temp_shuffle_916ba106-d48c-43fc-89d1-4abf471decd2\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/28/temp_shuffle_a4cd28b0-af1b-4250-aed6-6d1aa76ed4dc\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/34/temp_shuffle_a93faa15-d9aa-4dc5-b8c8-ae2d984e4d95\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/27/temp_shuffle_0d06d8cd-3601-469a-8e78-bbae6bd1cfde\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/15/temp_shuffle_a2ab9795-a67a-4900-951a-f57ef9787ccd\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3a/temp_shuffle_56d8b125-c988-4c05-a692-1f33ac5f550f\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/37/temp_shuffle_d9570049-ac7d-44d9-ad07-b0614ec9169d\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1e/temp_shuffle_de5bce82-9106-4008-922b-ef4dd08d1185\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2c/temp_shuffle_6b515239-ac8d-4fa7-a650-0e74c0948e18\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/06/temp_shuffle_fe075be8-6f4a-4da3-a0d3-eb8601520a75\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/36/temp_shuffle_41579304-bf11-4cb6-a230-4bae7f718950\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/22/temp_shuffle_1668caa9-e314-411e-9f8f-5e5d25f2b2d1\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/09/temp_shuffle_f27f4945-767a-408c-ada5-a2a46d823e88\n",
      "25/02/05 21:02:15 WARN TaskSetManager: Lost task 0.0 in stage 232.0 (TID 1556) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:02:15 WARN TaskSetManager: Lost task 1.0 in stage 232.0 (TID 1557) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/01/temp_shuffle_f872641c-5eb5-4e52-9ccc-bdf1e99236b5\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/28/temp_shuffle_76fda55d-94ce-42f9-830b-fb29962ec0dd\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0c/temp_shuffle_0d4cbabc-5e23-4113-8d4a-feb791c5aa7d\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3b/temp_shuffle_2f1e979c-0455-416a-925b-17c9bee0aa62\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/22/temp_shuffle_7e741c9e-6e57-4e76-9c11-23a61d28a8d1\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/25/temp_shuffle_4c43239f-6e76-444d-9e5c-21e7d73ccbd7\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/01/temp_shuffle_88871a51-2418-4d1c-8650-235ab5497d3d\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1c/temp_shuffle_29dc9de6-92db-468f-a9c2-ee573976b2bb\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2e/temp_shuffle_14cbb801-c79d-4bbf-aa09-a3840b0eb60e\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0e/temp_shuffle_6632dff2-2d95-4353-8dae-236d2266a5d6\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/17/temp_shuffle_b5f45e9d-aa01-4bf0-bd44-ca3aa1e968d9\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3c/temp_shuffle_d5a14df1-5c4f-449a-9de6-ed84e1c4a7c8\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/00/temp_shuffle_7ce46c23-d51e-4ec8-a55f-298028afcb01\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/21/temp_shuffle_97641368-432b-419d-aa60-c3b16635d2bd\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2f/temp_shuffle_1763a4bd-3454-4955-ae2d-ebd781691bea\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3d/temp_shuffle_83be27e9-e286-43ee-96d4-1de9247f43b9\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/20/temp_shuffle_3d777913-1b13-446b-b473-10593840348b\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1e/temp_shuffle_41b72b91-3815-45c3-8d35-85752a4b4c3e\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2d/temp_shuffle_e805c89e-a7fe-4e49-a61d-06b51b792b5c\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/22/temp_shuffle_a3cdb486-7a2a-4ee7-b029-19189b03e906\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/34/temp_shuffle_5f65ae93-a881-402c-8092-e02fa4e72593\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/05/temp_shuffle_92c41870-3bfb-4a91-8309-5be19653e52b\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/01/temp_shuffle_80c16790-cb67-4eba-a348-3bc16131c3b2\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0b/temp_shuffle_7591c1ce-1573-4660-9b0e-8407db664399\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0c/temp_shuffle_32ba4788-8b23-4d19-8480-d5ff55cc551a\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1b/temp_shuffle_6a203781-f085-4e83-bf10-53ac67771ef3\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1a/temp_shuffle_7b11434d-c9a6-4cda-9b1e-0132194a7a9e\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2a/temp_shuffle_415f52a3-d533-4b0d-a0e8-21ac2bb0b0ee\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/34/temp_shuffle_6cada235-35a0-4085-8c58-e527d4d76507\n",
      "25/02/05 21:02:15 WARN TaskSetManager: Lost task 2.0 in stage 232.0 (TID 1558) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/13/temp_shuffle_daa4a045-3fa5-4d48-934a-80759cc90897\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/02/temp_shuffle_40bb92c3-dc56-4810-9983-7570431857ef\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2e/temp_shuffle_5757143e-35b7-4523-ae50-1d2c2cd203b4\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/26/temp_shuffle_cc5fd8b2-0643-4aaa-961a-ce23486c2bab\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1d/temp_shuffle_fa0d2963-6a89-43cf-8beb-254ca1332cb9\n",
      "25/02/05 21:02:15 WARN TaskSetManager: Lost task 7.0 in stage 232.0 (TID 1563) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1a/temp_shuffle_1f96367b-f8ac-4aaa-9367-97a5aac6c1a9\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0f/temp_shuffle_eb14465a-d6fa-46bb-9c3e-807865e8c1fd\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1e/temp_shuffle_34645cd5-6e29-4868-b6da-3a4b72719855\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/11/temp_shuffle_2585769d-6847-41fa-a08e-e5b4bdb5cf16\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/0e/temp_shuffle_b342a06a-febb-430d-a977-9ff0503eb4df\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/15/temp_shuffle_c9a47ae5-83a4-4781-b5d2-fb74c2a327e0\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/01/temp_shuffle_34fc4bfc-f621-464e-923b-28971d31040b\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3f/temp_shuffle_19f336a4-1587-4d10-9305-254ace1fbc6f\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/28/temp_shuffle_bd9ed7d2-da5f-43b2-a741-b775c1291adf\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/29/temp_shuffle_0b981d96-1fc1-4799-9d98-cc4a90722cf7\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/09/temp_shuffle_f2cfbb40-07e9-4a54-814c-d5e67892aeb4\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/21/temp_shuffle_c80bf498-1119-4a2d-81c5-2e06bce9f60b\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/02/temp_shuffle_105d3fb4-ef9b-4ffa-b6b7-678d90092f14\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/05/temp_shuffle_694cd6a6-da40-4a12-9686-7dba90c84a62\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/28/temp_shuffle_33f79040-8fed-4052-a3cb-8ce410993f95\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3a/temp_shuffle_6ff7e9c1-ed5b-4af7-aa9d-a3491e24f7ef\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/07/temp_shuffle_32585942-8555-4e68-894b-fda3d480498f\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/28/temp_shuffle_7f479e56-357c-457a-8f6e-ae50c2021c17\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/30/temp_shuffle_686820d0-1ab2-40e6-84ce-6a9eed4460b4\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/28/temp_shuffle_7c2b4ee7-7632-43aa-a1c6-226a6f1c6b4e\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/14/temp_shuffle_9bc946a1-f9da-49d0-9b8a-39215e195db9\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/32/temp_shuffle_efa587c7-0a5b-4264-bd9a-d967c75e2416\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2d/temp_shuffle_7489584a-0354-49cc-9a81-084130d17ba9\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/2f/temp_shuffle_8bec7d41-60fe-415a-a510-9d4bf2ecade0\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/09/temp_shuffle_7d9a8133-09fe-41f5-b654-c69d89407423\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/30/temp_shuffle_a406f27c-2fc1-44e6-bb71-01c39e871273\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/03/temp_shuffle_87437e36-4190-45af-adc9-f78d3916e46c\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/09/temp_shuffle_92b17ebb-830b-4e05-8977-9eb9c5c8c234\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/3f/temp_shuffle_8a608a66-768f-4540-9ad6-d60293df2086\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/16/temp_shuffle_4fe7a7db-9cfd-487f-9f0d-750234fa6bc2\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/19/temp_shuffle_f9d4208f-4310-4659-96ce-1dc689c58a4b\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/17/temp_shuffle_0b3ab227-f370-4b91-b989-a85f4a451c12\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/31/temp_shuffle_0327a35e-66f7-4a81-9608-b3a514a0586b\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/33/temp_shuffle_98ed86c1-3e00-4095-89f6-cd0f17dc1f6b\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/1a/temp_shuffle_76c40d87-9a23-4788-a122-e6cbecbbf158\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/24/temp_shuffle_b68346db-1383-445e-8f09-afe65d3b6d75\n",
      "25/02/05 21:02:15 WARN DiskBlockObjectWriter: Error deleting /tmp/blockmgr-6c843af9-6468-4db8-9216-bf1b1a1717d1/06/temp_shuffle_0d38fb1d-0ece-4552-8e58-b3faa1a7d2a7\n",
      "25/02/05 21:02:15 WARN TaskSetManager: Lost task 6.0 in stage 232.0 (TID 1562) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:02:15 WARN TaskSetManager: Lost task 4.0 in stage 232.0 (TID 1560) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:02:15 WARN TaskSetManager: Lost task 5.0 in stage 232.0 (TID 1561) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:02:15 ERROR MergeIntoCommand: Fatal error in MERGE with materialized source in attempt 1.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 232.0 failed 1 times, most recent failure: Lost task 3.0 in stage 232.0 (TID 1559) (cloud3 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.<init>(UnsafeSorterSpillReader.java:50)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.getReader(UnsafeSorterSpillWriter.java:159)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.getSortedIterator(UnsafeExternalSorter.java:555)\n",
      "\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:172)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:779)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1(SortAggregateExec.scala:62)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1$adapted(SortAggregateExec.scala:59)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec$$Lambda$3769/0x00007f27e90862e8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$3770/0x00007f27e90868a8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2569/0x00007f27e8dbaab8.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.<init>(UnsafeSorterSpillReader.java:50)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.getReader(UnsafeSorterSpillWriter.java:159)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.getSortedIterator(UnsafeExternalSorter.java:555)\n",
      "\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:172)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:779)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1(SortAggregateExec.scala:62)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1$adapted(SortAggregateExec.scala:59)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec$$Lambda$3769/0x00007f27e90862e8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$3770/0x00007f27e90868a8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2569/0x00007f27e8dbaab8.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gabrielbarros/tp4/task3/ingest_v_delta.py\", line 147, in <module>\n",
      "    main()\n",
      "  File \"/home/gabrielbarros/tp4/task3/ingest_v_delta.py\", line 137, in main\n",
      "    time_for_update_gold_layer = update_gold_layer(spark, silver_output_path, gold_output_path)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gabrielbarros/tp4/task3/ingest_v_delta.py\", line 103, in update_gold_layer\n",
      "    merge_delta_table(\n",
      "  File \"/home/gabrielbarros/tp4/task3/ingest_v_delta.py\", line 51, in merge_delta_table\n",
      "    ).execute()\n",
      "      ^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/delta/tables.py\", line 1022, in execute\n",
      "    self._jbuilder.execute()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\", line 169, in deco\n",
      "    return f(*a, **kw)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o320.execute.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 232.0 failed 1 times, most recent failure: Lost task 3.0 in stage 232.0 (TID 1559) (cloud3 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.<init>(UnsafeSorterSpillReader.java:50)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.getReader(UnsafeSorterSpillWriter.java:159)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.getSortedIterator(UnsafeExternalSorter.java:555)\n",
      "\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:172)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:779)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1(SortAggregateExec.scala:62)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1$adapted(SortAggregateExec.scala:59)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec$$Lambda$3769/0x00007f27e90862e8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$3770/0x00007f27e90868a8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2569/0x00007f27e8dbaab8.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.<init>(UnsafeSorterSpillReader.java:50)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.getReader(UnsafeSorterSpillWriter.java:159)\n",
      "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.getSortedIterator(UnsafeExternalSorter.java:555)\n",
      "\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:172)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:779)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1(SortAggregateExec.scala:62)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1$adapted(SortAggregateExec.scala:59)\n",
      "\tat org.apache.spark.sql.execution.aggregate.SortAggregateExec$$Lambda$3769/0x00007f27e90862e8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:875)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$3770/0x00007f27e90868a8.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2569/0x00007f27e8dbaab8.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python3 /home/gabrielbarros/tp4/task3/ingest_v_delta.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c0705-11d1-4d94-bd16-509526c11e10",
   "metadata": {},
   "source": [
    "### Parquet x Delta Ingest V2 time comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea329f-44c4-4379-bd7c-f652de68698b",
   "metadata": {},
   "source": [
    "| Format  | Silver Layer (s) | Gold Layer (s) | Total Time (s) |\n",
    "|---------|-----------------|----------------|----------------|\n",
    "| Parquet | 25.89           | 10.29          | 49.45          |\n",
    "| Delta   | 39.01           | 18.15          | 79.97          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da1fd55-604f-40cd-bedb-ea63e12d1d33",
   "metadata": {},
   "source": [
    "## Update playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e3d331-a3d5-494d-bc81-d23fa80dedb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.11/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/gabrielbarros/.ivy2/cache\n",
      "The jars for the packages stored in: /home/gabrielbarros/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-191ec73d-3fc9-440b-b132-3fb7cda7781d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 204ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-191ec73d-3fc9-440b-b132-3fb7cda7781d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/5ms)\n",
      "25/02/05 21:02:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/05 21:02:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/02/05 21:02:18 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/02/05 21:02:18 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "25/02/05 21:02:18 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "[INFO] Updating datalake/silver Layer for playlist 11992...\n",
      "25/02/05 21:02:24 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[INFO] datalake/silver Layer updated in 11.51 seconds.                          \n",
      "[INFO] Updating datalake/gold Layer for playlist 11992...\n",
      "[INFO] datalake/gold Layer updated in 3.13 seconds.\n",
      "[INFO] Playlist 11992 update completed in 18.29 seconds.\n"
     ]
    }
   ],
   "source": [
    "! python3 /home/gabrielbarros/tp4/task3/update_playlist_delta.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7116050-05b5-493e-9511-82a30fbcded4",
   "metadata": {},
   "source": [
    "### Parquet x Delta time comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ce3f6-152c-427d-bba2-3bf09df453ca",
   "metadata": {},
   "source": [
    "| Format  | Silver Layer (s) | Gold Layer (s) | Total Time (s) |\n",
    "|---------|-----------------|----------------|----------------|\n",
    "| Parquet | 13.67           | 05.56          | 28.58          |\n",
    "| Delta   | 19.97           | 04.75          | 32.92          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c4d66-3a0d-4257-86d6-d2a6a048cb18",
   "metadata": {},
   "source": [
    "## Ingest V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91386a37-27fd-4de2-967d-58f0374e5ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.11/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/gabrielbarros/.ivy2/cache\n",
      "The jars for the packages stored in: /home/gabrielbarros/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-00d5afd7-c8d2-43a9-99c1-f92e99a10a7d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 189ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-00d5afd7-c8d2-43a9-99c1-f92e99a10a7d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/5ms)\n",
      "25/02/05 21:02:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/05 21:02:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/02/05 21:02:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/02/05 21:02:37 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "25/02/05 21:02:37 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "25/02/05 21:02:47 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/02/05 21:02:58 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/05 21:03:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/05 21:03:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:27 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/05 21:03:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/05 21:03:58 WARN TaskMemoryManager: Failed to allocate a page (8388608 bytes), try again.\n",
      "25/02/05 21:03:58 WARN TaskMemoryManager: Failed to allocate a page (8388608 bytes), try again.\n",
      "25/02/05 21:03:58 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again.\n",
      "25/02/05 21:03:58 ERROR Executor: Exception in task 0.0 in stage 232.0 (TID 1586)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "25/02/05 21:03:59 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 0.0 in stage 232.0 (TID 1586),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "25/02/05 21:03:59 WARN TaskSetManager: Lost task 0.0 in stage 232.0 (TID 1586) (cloud3 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\n",
      "25/02/05 21:03:59 ERROR TaskSetManager: Task 0 in stage 232.0 failed 1 times; aborting job\n",
      "25/02/05 21:03:59 WARN TaskSetManager: Lost task 7.0 in stage 232.0 (TID 1593) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:03:59 WARN TaskSetManager: Lost task 2.0 in stage 232.0 (TID 1588) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:03:59 WARN TaskSetManager: Lost task 4.0 in stage 232.0 (TID 1590) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:03:59 WARN TaskSetManager: Lost task 5.0 in stage 232.0 (TID 1591) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:03:59 WARN TaskSetManager: Lost task 3.0 in stage 232.0 (TID 1589) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:03:59 WARN TaskSetManager: Lost task 1.0 in stage 232.0 (TID 1587) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:03:59 WARN TaskSetManager: Lost task 6.0 in stage 232.0 (TID 1592) (cloud3 executor driver): TaskKilled (Stage cancelled)\n",
      "25/02/05 21:03:59 ERROR MergeIntoCommand: Fatal error in MERGE with materialized source in attempt 1.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 232.0 failed 1 times, most recent failure: Lost task 0.0 in stage 232.0 (TID 1586) (cloud3 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.lang.OutOfMemoryError: Java heap space\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gabrielbarros/tp4/task3/ingest_v_delta.py\", line 147, in <module>\n",
      "    spark.stop()\n",
      "    ^^^^^^\n",
      "  File \"/home/gabrielbarros/tp4/task3/ingest_v_delta.py\", line 137, in main\n",
      "    tracks_v2_df = spark.read.json(sample_tracks_v2)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gabrielbarros/tp4/task3/ingest_v_delta.py\", line 103, in update_gold_layer\n",
      "    [\"playlist_id\", \"num_tracks\", \"num_artists\", \"num_albums\", \"total_duration_ms\", \"name\", \"collaborative\", \"description\"]\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gabrielbarros/tp4/task3/ingest_v_delta.py\", line 51, in merge_delta_table\n",
      "    values={col: F.col(\"source.\" + col) for col in update_columns}\n",
      "      ^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/delta/tables.py\", line 1022, in execute\n",
      "    self._jbuilder.execute()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\", line 169, in deco\n",
      "    return f(*a, **kw)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o320.execute.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 232.0 failed 1 times, most recent failure: Lost task 0.0 in stage 232.0 (TID 1586) (cloud3 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: java.lang.OutOfMemoryError: Java heap space\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python3 /home/gabrielbarros/tp4/task3/ingest_v_delta.py -p \"/shared/sampled/playlists_v3.json\" -t \"/shared/sampled/tracks_v3.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cdd4a5-5e78-47b9-8c7c-d2b720bb431c",
   "metadata": {},
   "source": [
    "### Parquet x Delta time comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282229f-3cf0-4f6a-b510-9b574a4688db",
   "metadata": {},
   "source": [
    "| Format  | Silver Layer (s) | Gold Layer (s) | Total Time (s) |\n",
    "|---------|-----------------|----------------|----------------|\n",
    "| Parquet | 15.03           | 07.55          | 31.00          |\n",
    "| Delta   | 27.44           | 12.26          | 27.44          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642cba9a-7d9b-4d13-a024-73b2574d0b29",
   "metadata": {},
   "source": [
    "### Parquet x Delta space comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ccb06-565e-4361-8785-77e62c4babc5",
   "metadata": {},
   "source": [
    "| Format  | Bronze Layer (MB) | Silver Layer (MB) | Gold Layer (MB) | Total Storage (MB) |\n",
    "|---------|------------------|------------------|----------------|-----------------|\n",
    "| Parquet | 44.64            | 124.02           | 24.74          | 193.41          |\n",
    "| Delta   | 44.65            | 156.49           | 41.31          | 242.46          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bbb07d-7b29-4880-88a9-13df25b3e710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
